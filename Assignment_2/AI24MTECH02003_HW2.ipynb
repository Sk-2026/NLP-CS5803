{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, SimpleRNN, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (16777, 462)\n",
      "y_train shape (single-label): (16777,)\n",
      "X_test shape: (4195, 462)\n",
      "y_test shape (single-label): (4195,)\n",
      "Unique labels in y_train_single: (array([0, 1, 2, 3, 4, 5], dtype=int64), array([6902, 4391, 3538, 1422,  355,  169], dtype=int64))\n",
      "Unique labels in y_test_single: (array([0, 1, 2, 3, 4, 5], dtype=int64), array([1692, 1130,  898,  343,   92,   40], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = \"E:\\mtech\\CV\\Dataset-1.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"train\")\n",
    "\n",
    "# Combine TITLE and ABSTRACT for text processing\n",
    "df['text'] = df['TITLE'] + ' ' + df['ABSTRACT']\n",
    "\n",
    "# Labels for multi-label classification\n",
    "labels = ['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Tokenize text\n",
    "tokenized_text = [word_tokenize(text) for text in df['text']]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=2, workers=4)\n",
    "vocab_size = len(word2vec_model.wv)\n",
    "\n",
    "# Create word index\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matrix[i] = word2vec_model.wv[word]\n",
    "\n",
    "# Prepare labels\n",
    "y = df[labels].values  # One-hot encoded labels\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert one-hot labels to categorical labels (0-5)\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print shapes and unique values\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape (single-label):\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape (single-label):\", y_test.shape)\n",
    "\n",
    "print(\"Unique labels in y_train_single:\", np.unique(y_train,return_counts=True))\n",
    "print(\"Unique labels in y_test_single:\", np.unique(y_test,return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 98ms/step - accuracy: 0.2101 - loss: 1.7849 - val_accuracy: 0.0095 - val_loss: 1.8038\n",
      "Epoch 2/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 106ms/step - accuracy: 0.0907 - loss: 1.8176 - val_accuracy: 0.4033 - val_loss: 1.7853\n",
      "Epoch 3/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 124ms/step - accuracy: 0.1795 - loss: 1.7851 - val_accuracy: 0.0095 - val_loss: 1.7933\n",
      "Epoch 4/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 105ms/step - accuracy: 0.1640 - loss: 1.7475 - val_accuracy: 0.0095 - val_loss: 1.7929\n",
      "Epoch 5/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 102ms/step - accuracy: 0.0480 - loss: 1.8000 - val_accuracy: 0.0095 - val_loss: 1.7931\n",
      "Epoch 6/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 130ms/step - accuracy: 0.0335 - loss: 1.8100 - val_accuracy: 0.4033 - val_loss: 1.7900\n",
      "Epoch 7/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 132ms/step - accuracy: 0.1668 - loss: 1.7951 - val_accuracy: 0.0818 - val_loss: 1.7900\n",
      "Epoch 8/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 130ms/step - accuracy: 0.1445 - loss: 1.8172 - val_accuracy: 0.2694 - val_loss: 1.7899\n",
      "Epoch 9/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 113ms/step - accuracy: 0.0972 - loss: 1.8273 - val_accuracy: 0.0818 - val_loss: 1.7897\n",
      "Epoch 10/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 110ms/step - accuracy: 0.0837 - loss: 1.8407 - val_accuracy: 0.4033 - val_loss: 1.7892\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step\n",
      "\n",
      "Classification Report for LSTM:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.40      1.00      0.57      1692\n",
      "             Physics       0.00      0.00      0.00      1130\n",
      "         Mathematics       0.00      0.00      0.00       898\n",
      "          Statistics       0.00      0.00      0.00       343\n",
      "Quantitative Biology       0.00      0.00      0.00        92\n",
      "Quantitative Finance       0.00      0.00      0.00        40\n",
      "\n",
      "            accuracy                           0.40      4195\n",
      "           macro avg       0.07      0.17      0.10      4195\n",
      "        weighted avg       0.16      0.40      0.23      4195\n",
      "\n",
      "\n",
      "Training GRU model...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 128ms/step - accuracy: 0.2002 - loss: 1.7804 - val_accuracy: 0.0219 - val_loss: 1.7936\n",
      "Epoch 2/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 129ms/step - accuracy: 0.1983 - loss: 1.7790 - val_accuracy: 0.0219 - val_loss: 1.7958\n",
      "Epoch 3/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 129ms/step - accuracy: 0.1462 - loss: 1.7583 - val_accuracy: 0.0219 - val_loss: 1.7978\n",
      "Epoch 4/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 130ms/step - accuracy: 0.0476 - loss: 1.7827 - val_accuracy: 0.0219 - val_loss: 1.7949\n",
      "Epoch 5/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 130ms/step - accuracy: 0.1258 - loss: 1.7912 - val_accuracy: 0.0818 - val_loss: 1.7910\n",
      "Epoch 6/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 108ms/step - accuracy: 0.1031 - loss: 1.7881 - val_accuracy: 0.4033 - val_loss: 1.7909\n",
      "Epoch 7/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 107ms/step - accuracy: 0.1329 - loss: 1.8079 - val_accuracy: 0.0219 - val_loss: 1.7940\n",
      "Epoch 8/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 107ms/step - accuracy: 0.1739 - loss: 1.7628 - val_accuracy: 0.0818 - val_loss: 1.7921\n",
      "Epoch 9/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 106ms/step - accuracy: 0.0255 - loss: 1.8077 - val_accuracy: 0.2141 - val_loss: 1.7916\n",
      "Epoch 10/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 106ms/step - accuracy: 0.1368 - loss: 1.8129 - val_accuracy: 0.2141 - val_loss: 1.7915\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step\n",
      "\n",
      "Classification Report for GRU:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.00      0.00      0.00      1692\n",
      "             Physics       0.00      0.00      0.00      1130\n",
      "         Mathematics       0.21      1.00      0.35       898\n",
      "          Statistics       0.00      0.00      0.00       343\n",
      "Quantitative Biology       0.00      0.00      0.00        92\n",
      "Quantitative Finance       0.00      0.00      0.00        40\n",
      "\n",
      "            accuracy                           0.21      4195\n",
      "           macro avg       0.04      0.17      0.06      4195\n",
      "        weighted avg       0.05      0.21      0.08      4195\n",
      "\n",
      "\n",
      "Training RNN model...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.1705 - loss: 1.8962 - val_accuracy: 0.1142 - val_loss: 1.7279\n",
      "Epoch 2/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.1538 - loss: 1.8087 - val_accuracy: 0.0462 - val_loss: 1.8137\n",
      "Epoch 3/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.1379 - loss: 1.8292 - val_accuracy: 0.1290 - val_loss: 1.7866\n",
      "Epoch 4/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.1082 - loss: 1.8223 - val_accuracy: 0.0095 - val_loss: 1.8136\n",
      "Epoch 5/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.0652 - loss: 1.7792 - val_accuracy: 0.1447 - val_loss: 1.8018\n",
      "Epoch 6/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.1059 - loss: 1.7627 - val_accuracy: 0.0138 - val_loss: 1.8146\n",
      "Epoch 7/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.0668 - loss: 1.8102 - val_accuracy: 0.1487 - val_loss: 1.7909\n",
      "Epoch 8/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 30ms/step - accuracy: 0.0957 - loss: 1.8231 - val_accuracy: 0.1681 - val_loss: 1.7656\n",
      "Epoch 9/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.1317 - loss: 1.8318 - val_accuracy: 0.1993 - val_loss: 1.7909\n",
      "Epoch 10/10\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 30ms/step - accuracy: 0.0824 - loss: 1.7736 - val_accuracy: 0.0148 - val_loss: 1.8010\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "\n",
      "Classification Report for RNN:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.00      0.00      0.00      1692\n",
      "             Physics       0.00      0.00      0.00      1130\n",
      "         Mathematics       0.00      0.00      0.00       898\n",
      "          Statistics       0.00      0.00      0.00       343\n",
      "Quantitative Biology       0.02      0.43      0.04        92\n",
      "Quantitative Finance       0.01      0.55      0.02        40\n",
      "\n",
      "            accuracy                           0.01      4195\n",
      "           macro avg       0.00      0.16      0.01      4195\n",
      "        weighted avg       0.00      0.01      0.00      4195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sai_kiran_kocherla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Model training function\n",
    "def build_and_train_model(model_type):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, weights=[embedding_matrix],\n",
    "                        input_length=max_length, trainable=False))\n",
    "\n",
    "    if model_type == \"LSTM\":\n",
    "        model.add(LSTM(128, return_sequences=False))\n",
    "    elif model_type == \"GRU\":\n",
    "        model.add(GRU(128, return_sequences=False))\n",
    "    elif model_type == \"RNN\":\n",
    "        model.add(SimpleRNN(128, return_sequences=False))\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6, activation='softmax'))  # 6 output classes\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "    # Train with class weights to balance dataset\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test),\n",
    "              verbose=1, class_weight=class_weight_dict)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train and evaluate models\n",
    "for model_type in [\"LSTM\", \"GRU\", \"RNN\"]:\n",
    "    print(f\"\\nTraining {model_type} model...\")\n",
    "    model = build_and_train_model(model_type)\n",
    "    \n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)  # Get predicted class index\n",
    "    print(f\"\\nClassification Report for {model_type}:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
